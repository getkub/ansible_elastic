Ask,Description,What's the use,Splunk SPL Example,Elastic ESQL probable example
summaryindex,"Creates summary data and stores it in a summary index for faster searches. Legacy transforms is complex","Improves query speed by storing aggregated data in a dedicated index.","| summaryindex spool=f index=summary_idx | stats count by host","FROM firewall_index | STATS count = COUNT(*) BY host, rule.id, source.ip| eval env='prod' | summaryindex indexname=summary_firewall "
join,"Combines results from two searches based on common fields","Combines data from multiple datasets for richer context.","search index=web | join sessionid [search index=app | fields sessionid, userid]","FROM web | JOIN type=left [  FROM app | STATS count BY user, sessionid ] ON sessionid"
inlinestats/eventstats,"Adds statistical information to each event without changing the number of events","Adds calculated fields to each event without reducing event count.","| eventstats avg(response_time) as avg_resp by host","FROM logs | INLINESTATS distinct(countries) as country_list by host| STATS count(*) by country_list, host, language"
jq/json parser/kv/yaml extract,"Extracts and manipulates JSON data within events","Parses and extracts JSON fields for easier querying.","| eval parsed=spath(_raw, ""data.user.name"")","FROM logs | EVAL parsed = _raw.data.user.name"
macros/functions,"Reusable search fragments defined as macros","Encapsulates reusable query logic to simplify searches.","``get_failed_logins(index, timeframe)``","FROM logs | FUNCTION get_failed_logins(""logs"", ""1h"")"
scheduling using cron,"Currently we cannot configure jobs at clock time — applies to scheduling system, not search language","Allows scheduled queries to run at precise times using cron expressions.","(Splunk scheduling in savedsearches — cron: 0 8 * * *)","(Not supported natively in Elastic ESQL as of now; requires external scheduler like Kibana Task Manager or Watcher API)"
append/union,"Appends results from a second search to the first. This is important when values are empty after pipe, but still has to continue","Merges datasets even when one search returns no results.","search index=errors | append [search index=warnings]","FROM errors | UNION FROM warnings"
transaction,"Groups events into transactions based on common fields and time proximity","Tracks related events across time for session or workflow analysis.","| transaction sessionid startswith=""login"" endswith=""logout"" maxspan=30m","FROM logs | TRANSACTION BY sessionid TIMESPAN 30m START login END logout"
inputlookup/lookupfile,"Loads data from external CSV files or lookup tables","Enriches events with external reference data.","| inputlookup users.csv | where active=""true""","FROM FILE(""users.csv"") | WHERE active == ""true"""
subsearch,"Performs a search within another search","Filters main results based on another query’s output.","search index=web NOT [search index=blocked_ips | fields ip]","FROM web | WHERE ip NOT IN (FROM blocked_ips | KEEP ip)"
alert_actions (email),"Triggers email alert actions directly from search pipeline","Automatically sends email notifications when conditions are met within search","| alert_actions email ""to=admin@company.com subject='Alert' message='High CPU detected'""","FROM logs | WHERE cpu > 90 | ALERT EMAIL to=""admin@company.com"" subject=""Alert"""
alert_actions (webhook),"Sends HTTP requests to external APIs as part of search pipeline","Pushes alerts to external systems for automation or integration.","| alert_actions webhook ""url=https://api.slack.com/webhook connection=abc""","FROM logs | WHERE error_count > 100 | ALERT WEBHOOK url=""https://api.slack.com/webhook"""
